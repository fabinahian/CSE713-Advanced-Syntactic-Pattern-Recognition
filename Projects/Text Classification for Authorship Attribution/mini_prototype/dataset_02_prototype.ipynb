{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charles_dickens-great_expectations.txt',\n",
       " 'charles_dickens-oliver_twist.txt',\n",
       " 'charles_dickens-sketches_of_young_couples.txt',\n",
       " 'charles_dickens-somebodys_luggage.txt',\n",
       " 'charles_dickens-the_mystery_of_edwin_drood.txt',\n",
       " 'f_scott_fitzgerald-the_beautiful_and_damned.txt',\n",
       " 'f_scott_fitzgerald-the_great_gatsby.txt',\n",
       " 'f_scott_fitzgerald-this_side_of_paradise.txt',\n",
       " 'george_eliot-middlemarch.txt',\n",
       " 'george_eliot-silas_marner.txt',\n",
       " 'george_eliot-the_mill_on_the_floss.txt',\n",
       " 'james_joyce-a_portrait_of_the_artist_as_a_young_man.txt',\n",
       " 'james_joyce-dubliners.txt',\n",
       " 'james_joyce-ulysses.txt',\n",
       " 'jane_austen-emma.txt',\n",
       " 'jane_austen-pride_and_prejudice.txt',\n",
       " 'jane_austen-sense_and_sensibility.txt',\n",
       " 'joseph_conrad-heart_of_darkness.txt',\n",
       " 'joseph_conrad-lord_jim.txt',\n",
       " 'joseph_conrad-the_rover.txt',\n",
       " 'mark_twain-adventures_of_huckleberry_finn.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_1.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_2.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_3.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_4.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_5.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_6.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_7.txt',\n",
       " 'mark_twain-the_adventures_of_tom_sawyer_part_8.txt',\n",
       " 'mark_twain-the_tragedy_of_puddnhead_wilson.txt',\n",
       " 'oscar_wilde-an_ideal_husband.txt',\n",
       " 'oscar_wilde-the_importance_of_being_earnest__a_trivial_comedy_for_serious_people.txt',\n",
       " 'oscar_wilde-the_picture_of_dorian_gray.txt',\n",
       " 'virginia_woolf-mrs_dalloway.txt',\n",
       " 'virginia_woolf-night_and_day.txt',\n",
       " 'virginia_woolf-the_voyage_out.txt',\n",
       " 'william_shakespeare-alls_well_that_ends_well.txt',\n",
       " 'william_shakespeare-macbeth.txt',\n",
       " 'william_shakespeare-the_merry_wives_of_windsor.txt']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_list = os.listdir(\"W:\\CSE713-Advanced-Syntactic-Pattern-Recognition\\Projects\\Text Classification for Authorship Attribution\\dataset_02_personally_collected_data\\data_before_processing\")\n",
    "book_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Book Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Book Name           Author\n",
      "0          great expectations  charles dickens\n",
      "1                oliver twist  charles dickens\n",
      "2   sketches of young couples  charles dickens\n",
      "3           somebodys luggage  charles dickens\n",
      "4  the mystery of edwin drood  charles dickens\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse the filename to extract the author and book name.\n",
    "    Assumes filename format is 'name-of-author_book-name.txt'\n",
    "    \"\"\"\n",
    "    # Remove the file extension and split by the first underscore\n",
    "    author, book_name = filename[:-4].split('-', 1)\n",
    "    # Replace hyphens with spaces for author and book name\n",
    "    author = author.replace('_', ' ')\n",
    "    book_name = book_name.replace('_', ' ')\n",
    "    return book_name, author\n",
    "\n",
    "def process_files_for_metadata(directory):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            book_name, author = parse_filename(filename)\n",
    "            data.append({'Book Name': book_name, 'Author': author})\n",
    "    return data\n",
    "\n",
    "def create_metadata_dataframe(data):\n",
    "    \"\"\"\n",
    "    Create a dataframe from the provided metadata list\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Change 'your-directory-path' to the path of the directory containing your txt files\n",
    "directory_path = 'W:\\CSE713-Advanced-Syntactic-Pattern-Recognition\\Projects\\Text Classification for Authorship Attribution\\dataset_02_personally_collected_data\\data_before_processing'\n",
    "metadata = process_files_for_metadata(directory_path)\n",
    "metadata_df = create_metadata_dataframe(metadata)\n",
    "print(metadata_df.head())\n",
    "metadata_df.to_csv('../dataset_02_personally_collected_data/data_after_processing/books_df.csv', index=False)  # Save the dataframe to a CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sentence Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text    Label\n",
      "0                                        ﻿Chapter I.  charles\n",
      "1  My father’s family name being Pirrip, and my C...  charles\n",
      "2  So, I called myself Pip, and came to be called...  charles\n",
      "3  I give Pirrip as my father’s family name, on t...  charles\n",
      "4           Joe Gargery, who married the blacksmith.  charles\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def extract_author(filename):\n",
    "    \"\"\"\n",
    "    Extract the author's name from the filename.\n",
    "    Assumes filename format is 'name-of-author_book-name.txt'\n",
    "    \"\"\"\n",
    "    return filename.split('_')[0].replace('-', ' ')\n",
    "\n",
    "def process_files(directory):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            author = extract_author(filename)\n",
    "            path = os.path.join(directory, filename)\n",
    "            with open(path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                sentences = sent_tokenize(text)\n",
    "                if len(sentences) > 200:\n",
    "                    sampled_sentences = sentences[:200]\n",
    "                else:\n",
    "                    sampled_sentences = sentences\n",
    "                for sentence in sampled_sentences:\n",
    "                    data.append({'Text': sentence, 'Label': author})\n",
    "    return data\n",
    "\n",
    "def create_dataframe(data):\n",
    "    \"\"\"\n",
    "    Create a dataframe from the provided data list\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Change 'your-directory-path' to the path of the directory containing your txt files\n",
    "directory_path = '../dataset_02_personally_collected_data\\data_before_processing'\n",
    "data = process_files(directory_path)\n",
    "df = create_dataframe(data)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My father’s family name being Pirrip, and my Christian name Philip, my\\ninfant tongue could make of both names nothing longer or more explicit\\nthan Pip.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking first sentences\n",
    "df[\"Text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['charles', 'f', 'george', 'james', 'jane', 'joseph', 'mark',\n",
       "       'oscar', 'virginia', 'william'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dataset_02_personally_collected_data/data_after_processing/', index=False)  # Save the dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
